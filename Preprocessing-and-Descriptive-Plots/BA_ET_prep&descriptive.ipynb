{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**READ ME (provided by Aitana Grasso Cladera)**  \n",
        "You will receive 7 .CSV files. Most files’ structure is 59x176 (participants/trials). Test trials have already been removed. 59 corresponds to participants. However, we recorded 61. Two participants were excluded due to bad eye data (Subjects 22 and 61, with less than 90% of valid data).\n",
        "\n",
        "1. dominantEye = 122x1 (this follows the same structure as the behavioral data. Here, the data is duplicated (rows 1 and 2 correspond to Participant 1); you should consider this when doing your analysis. 1 means Right, and 0 means Left.\n",
        "2. onsetTimePicture = 59x176 (participants/trials). This shows the time on the computer clock when the picture was presented. The unit is random.\n",
        "Remember that for us, the time of picture onset represents time 0 and that we have a sampling rate of 500 Hz. This information should be enough to compute reaction times.\n",
        "3. onsetTimeSaccade = 59x176 (participants/trials). This shows the time on the computer clock when the first valid saccade was made. The unit is random.\n",
        "4. sideLookedLeftEye = 59x176 (participants/trials). This shows the side that was looked for the participant according to the information provided by the left eye. 1 means Right, and 0 means Left.\n",
        "5. sideLookedRightEye = 59x176 (participants/trials). This shows the side that was looked for the participant according to the information provided by the right eye. 1 means Right, and 0 means Left.\n",
        "Consider the dominant eye information here.\n",
        "6. valenceLeftEye = 59x176 (participants/trials). This shows the emotional valence of the picture that was on the side that the participant looked at first, according to the information provided by the left eye. 1 means Positive, and 0 means Negative.\n",
        "7. valenceRightEye = 59x176 (participants/trials). This shows the emotional valence of the picture that was on the side that the participant looked at first, according to the information provided by the right eye. 1 means Positive, and 0 means Negative.\n",
        "\n",
        "The information provided by left and and right eyes should match. It can be the case that they don’t match because the going over the threshold did not occur at the same time. This is why we only consider the information coming from the dominant eye.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fVGdOMPYn5IO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktE0jup6kiHF"
      },
      "outputs": [],
      "source": [
        "### MY CODE\n",
        "\n",
        "# --- Import Libraries and Data ---\n",
        "\n",
        "import scipy.io\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dominant Eye (122x1)\n",
        "dominant_eye_raw = pd.read_csv('/YOUR_PATH/dominantEye_Task2Exp1.csv', header=None)\n",
        "# Onset Time Picture (59x176)\n",
        "onset_time_picture_raw = pd.read_csv('/YOUR_PATH/onsetTimePicture_Task2Exp1.csv', header=None)\n",
        "# Onset Time Saccade (59x176)\n",
        "onset_time_saccade_raw = pd.read_csv('/YOUR_PATH/onsetTimeSaccade_Task2Exp1.csv', header=None)\n",
        "# Side Looked Left Eye (59x176)\n",
        "side_looked_left_eye_raw = pd.read_csv('/YOUR_PATH/sideLookedLeftEye_Task2Exp1.csv', header=None)\n",
        "# Side Looked Right Eye (59x176)\n",
        "side_looked_right_eye_raw = pd.read_csv('/YOUR_PATH/sideLookedRightEye_Task2Exp1.csv', header=None)\n",
        "# Valence Left Eye (59x176)\n",
        "valence_left_eye_raw = pd.read_csv('/YOUR_PATH/valenceLeftEye_Task2Exp1.csv', header=None)\n",
        "# Valence Right Eye (59x176)\n",
        "valence_right_eye_raw = pd.read_csv('/YOUR_PATH/valenceRightEye_Task2Exp1.csv', header=None)\n",
        "# Sequence of positive images (92x122)\n",
        "sequence_positive_images_raw = pd.read_csv('/YOUR_PATH/positiveSequence_Task2Exp1.csv', header=None)\n",
        "# Sequence of negative images (92x122)\n",
        "sequence_negative_images_raw = pd.read_csv('/YOUR_PATH/negativeSequence_Task2Exp1.csv', header=None)\n",
        "\n",
        "\n",
        "# get arousal ratings\n",
        "arousal_ratings = pd.read_csv('/YOUR_PATH/median_arousal_ratings.csv')\n",
        "arousal_dict = dict(zip(arousal_ratings['img_id'], arousal_ratings['arousal_levels']))"
      ],
      "metadata": {
        "id": "fvxYQLQ8oifm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Functions ---\n",
        "\n",
        "def participants_to_trials(participants):\n",
        "  '''Returns the blocks for the respective participants\n",
        "\n",
        "  Args:\n",
        "  participants: a list containing the participant ids\n",
        "\n",
        "  Resturns:\n",
        "  trials: a list of the trials from the participant\n",
        "  '''\n",
        "  trials = []\n",
        "  for i in range(len(participants)):\n",
        "    trials.append((participants[i]-1)*2)\n",
        "    trials.append((participants[i]-1)*2+1)\n",
        "  return trials\n",
        "\n",
        "\n",
        "def reshape_image_sequence_data(data):\n",
        "  '''Reshapes the image sequence data from 88x122 to 61x176\n",
        "\n",
        "  Args:\n",
        "  data: the image sequence data\n",
        "\n",
        "  Returns:\n",
        "  reshaped_data: a dataframe containing the reshaped image sequence\n",
        "  '''\n",
        "  reshaped_data = []\n",
        "\n",
        "  for block in range(0, len(data.columns), 2):\n",
        "    col1, col2 = data.iloc[:, block], data.iloc[:, block+1]\n",
        "    joint_blocks = pd.concat([col1, col2], ignore_index=True)\n",
        "    reshaped_data.append(joint_blocks)\n",
        "\n",
        "  return pd.DataFrame(reshaped_data)\n"
      ],
      "metadata": {
        "id": "up4_4CNjMIcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preprocessing the Eye Tracking Data ---\n",
        "\n",
        "# 1. Exclude test trials from positive and negative image sequence data\n",
        "\n",
        "# remove test trials\n",
        "sequence_positive_images = sequence_positive_images_raw.drop(range(4), axis=0)\n",
        "sequence_negative_images = sequence_negative_images_raw.drop(range(4), axis=0)\n",
        "# reset indices\n",
        "sequence_positive_images.reset_index(drop=True, inplace=True)\n",
        "sequence_negative_images.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# reshapes image sequence data to match structure of other data\n",
        "reshaped_pos_img_seq = reshape_image_sequence_data(sequence_positive_images)\n",
        "reshaped_neg_img_seq = reshape_image_sequence_data(sequence_negative_images)"
      ],
      "metadata": {
        "id": "FwKDepsPeRPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Remove participant\n",
        "# remove participants 22 and 61 from dominant_eye data because of little valid data\n",
        "# remove participants 41, 43 and 44 from all data because of accuracy < 90% in Classic AAT\n",
        "\n",
        "# exclude Participants 22 and 61\n",
        "rows_to_drop_a = participants_to_trials([22,61])\n",
        "dominant_eye = dominant_eye_raw.drop(rows_to_drop_a, axis=0)\n",
        "reshaped_neg_img_seq = reshaped_neg_img_seq.drop([22-1,61-1], axis=0)\n",
        "reshaped_pos_img_seq = reshaped_pos_img_seq.drop([22-1,61-1], axis=0)\n",
        "\n",
        "# reset indices\n",
        "dominant_eye.reset_index(drop=True, inplace=True)\n",
        "reshaped_neg_img_seq.reset_index(drop=True, inplace=True)\n",
        "reshaped_pos_img_seq.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# exclude Participants 41,43 and 44\n",
        "# since participants 22 and 61 have already been dropped all participants are shifted one to the left for part > 21\n",
        "rows_to_drop_b = participants_to_trials([41-1,43-1,44-1])\n",
        "dominant_eye = dominant_eye.drop(rows_to_drop_b, axis=0)\n",
        "participants_to_drop = [41-2, 43-2, 44-2] # -2 because indexing is 0-based and participants shifted to the left by 1\n",
        "onset_time_picture = onset_time_picture_raw.drop(participants_to_drop, axis=0)\n",
        "onset_time_saccade = onset_time_saccade_raw.drop(participants_to_drop, axis=0)\n",
        "side_looked_left_eye = side_looked_left_eye_raw.drop(participants_to_drop, axis=0)\n",
        "side_looked_right_eye = side_looked_right_eye_raw.drop(participants_to_drop, axis=0)\n",
        "\n",
        "valence_left_eye = valence_left_eye_raw.drop(participants_to_drop, axis=0)\n",
        "valence_right_eye = valence_right_eye_raw.drop(participants_to_drop, axis=0)\n",
        "reshaped_neg_img_seq = reshaped_neg_img_seq.drop(participants_to_drop, axis=0)\n",
        "reshaped_pos_img_seq = reshaped_pos_img_seq.drop(participants_to_drop, axis=0)\n",
        "\n",
        "# reset indices\n",
        "onset_time_picture.reset_index(drop=True, inplace=True)\n",
        "onset_time_saccade.reset_index(drop=True, inplace=True)\n",
        "side_looked_left_eye.reset_index(drop=True, inplace=True)\n",
        "side_looked_right_eye.reset_index(drop=True, inplace=True)\n",
        "valence_left_eye.reset_index(drop=True, inplace=True)\n",
        "valence_right_eye.reset_index(drop=True, inplace=True)\n",
        "dominant_eye.reset_index(drop=True, inplace=True)\n",
        "reshaped_pos_img_seq.reset_index(drop=True, inplace=True)\n",
        "reshaped_neg_img_seq.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 3. Compute the first fixation reaction times\n",
        "\n",
        "rt_eye_movement = (onset_time_saccade - onset_time_picture)"
      ],
      "metadata": {
        "id": "92yi51P9LgiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Derive the Valence, Arousal, and Side information from the dominant eye\n",
        "\n",
        "# create dominant_eye_part 59x1 (59 participants) out of out of dominant_eye 122x1 (122 blocks) by taking every second entry\n",
        "# this is neccessary because for the ET Data we only have one block per participant (all other data frames have the structure 59x176)\n",
        "dominant_eye_part = pd.DataFrame(dominant_eye.values[::2].flatten())\n",
        "\n",
        "# create empty arrays with the same shape\n",
        "side_looked = np.empty_like(side_looked_right_eye)\n",
        "valence_looked = np.empty_like(valence_right_eye)\n",
        "arousal_looked = np.empty_like(valence_right_eye)\n",
        "arousal_difference = np.empty_like(valence_right_eye)\n",
        "picture_looked = np.empty_like(valence_right_eye)\n",
        "\n",
        "# create side_looked and valence_looked that contains the information from the dominant eye\n",
        "\n",
        "# go through participants\n",
        "for i in range(len(dominant_eye_part)):\n",
        "  # go through 176 trials\n",
        "  for j in range(len(side_looked_right_eye.columns)):\n",
        "\n",
        "    # if the right eye is dominant save right eye information for side_looked and valence_looked\n",
        "    if dominant_eye_part.iloc[i, 0] == 1:\n",
        "        side_looked[i,j] = side_looked_right_eye.iloc[i, j]\n",
        "        valence_looked[i,j] = valence_right_eye.iloc[i, j]\n",
        "\n",
        "    # if the left eye is dominant save information of left eye\n",
        "    else:\n",
        "        side_looked[i,j] = side_looked_left_eye.iloc[i, j] # save the side the left eye looked at in side_looked\n",
        "        valence_looked[i,j] = valence_left_eye.iloc[i, j] # save the valence the left eye looked at in valence_looked\n",
        "\n",
        "    # if the positive image was looked at get the respective arousal rating from the positive image sequence\n",
        "    if valence_looked[i,j] == 1: # valence 1 = positive\n",
        "      picture_looked[i,j] = reshaped_pos_img_seq.iloc[i, j]\n",
        "      arousal_looked[i,j] = arousal_dict.get(reshaped_pos_img_seq.iloc[i, j])\n",
        "\n",
        "      # compute Arousal-Difference\n",
        "      # (-) indicates looked image is smaller in arousal than not-looked image, (+) indicates looked image is higher\n",
        "      arousal_difference[i,j] = arousal_dict.get(reshaped_pos_img_seq.iloc[i, j]) - arousal_dict.get(reshaped_neg_img_seq.iloc[i, j])\n",
        "\n",
        "    # and if the negative image was looked at get the respective arousal rating from the negative image sequence\n",
        "    else: # valence 0 = negative\n",
        "      picture_looked[i,j] = reshaped_neg_img_seq.iloc[i, j]\n",
        "      arousal_looked[i,j] = arousal_dict.get(reshaped_neg_img_seq.iloc[i, j])\n",
        "\n",
        "      # compute Arousal-Difference\n",
        "      # (-) indicates looked image is smaller in arousal than not-looked image, (+) indicates looked image is higher\n",
        "      arousal_difference[i,j] = arousal_dict.get(reshaped_neg_img_seq.iloc[i, j]) - arousal_dict.get(reshaped_pos_img_seq.iloc[i, j])\n",
        "\n",
        "# turn into a data frame\n",
        "side_looked = pd.DataFrame(side_looked)\n",
        "valence_looked = pd.DataFrame(valence_looked)\n",
        "arousal_looked = pd.DataFrame(arousal_looked)\n",
        "arousal_difference = pd.DataFrame(arousal_difference)\n",
        "picture_looked = pd.DataFrame(picture_looked)\n"
      ],
      "metadata": {
        "id": "gkRkEwMhbDne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Exclude very fast reaction times (RTs < 2 std deviations from the mean)\n",
        "\n",
        "# compute the bound and set respective reaction times to NaN\n",
        "global_mean = np.nanmean(rt_eye_movement.values)\n",
        "global_std = np.nanstd(rt_eye_movement.values)\n",
        "lower_bound = global_mean - 2 * global_std\n",
        "rt_eye_movement[rt_eye_movement < lower_bound] = np.nan\n",
        "\n",
        "# 6. Log-transform the data using log10\n",
        "\n",
        "# flatten and clean the data\n",
        "reaction_times_flat_untransformed = rt_eye_movement.values.flatten()\n",
        "reaction_times_flat_untransformed = reaction_times_flat_untransformed[~np.isnan(reaction_times_flat_untransformed)]\n",
        "\n",
        "# log-transform the data and clean and flatten\n",
        "reaction_time_log_transformed = rt_eye_movement.applymap(\n",
        "    lambda x: np.log10(x) if pd.notna(x) and x > 0 else np.nan\n",
        ")\n",
        "reaction_times_flat_log = reaction_time_log_transformed.values.flatten()\n",
        "reaction_times_flat_log = reaction_times_flat_log[~np.isnan(reaction_times_flat_log)]\n",
        "\n",
        "# --- plot the log-transformed and untransformed distribution ---\n",
        "\n",
        "# create a plot\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "sns.histplot(reaction_times_flat_untransformed, kde=True, bins=30, color='lightblue', alpha=0.7, label='non-transformed')\n",
        "\n",
        "# create a second axis for the log-transformed reaction time distribution\n",
        "ax2 = ax1.twiny()\n",
        "sns.histplot(reaction_times_flat_log, kde=True, bins=30, color='dodgerblue', alpha=0.7, label='log-transformed', ax=ax2)\n",
        "\n",
        "# define plot labels and design details\n",
        "ax1.set_xlabel(\"Reaction Time (ms)\", fontsize=12)\n",
        "ax2.set_xlabel(\"Reaction Time (log-transformed)\", fontsize=12)\n",
        "ax1.set_ylabel(\"Frequency\", fontsize = 12)\n",
        "fig.legend(loc='upper right', bbox_to_anchor=(0.89, 0.87), fontsize=12)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# --- Save the Eye Tracking Data in a Data Frame ---\n",
        "\n",
        "# initialize a list to create the data frame\n",
        "data_frame_ET = []\n",
        "\n",
        "# go through participants\n",
        "for participant in range(len(rt_eye_movement)):\n",
        "\n",
        "    # go through trials and save all the information for each trial\n",
        "    for trial in range(len(rt_eye_movement.columns)):\n",
        "        data_frame_ET.append({\n",
        "            'participant_id': participant+1, # so that participants start at 1 and not 0\n",
        "            'picture_looked': picture_looked.iloc[participant, trial],\n",
        "            'rt': rt_eye_movement.iloc[participant, trial],\n",
        "            'log-transformed rt': reaction_time_log_transformed.iloc[participant, trial],\n",
        "            'side_looked': side_looked.iloc[participant, trial],\n",
        "            'valence_looked': valence_looked.iloc[participant, trial],\n",
        "            'arousal_looked': arousal_looked.iloc[participant, trial],\n",
        "            'arousal_difference': arousal_difference.iloc[participant, trial]\n",
        "        })\n",
        "\n",
        "# turn into a data frame\n",
        "df_ET = pd.DataFrame(data_frame_ET)\n",
        "\n",
        "# remove NaN rows\n",
        "df_ET = df_ET.dropna()\n",
        "\n",
        "# safe the data frame as a csv file\n",
        "#df_ET.to_csv(\"/YOUR_PATH/EyeTrackingData_T2.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "ABeCtoV4DxRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Descriptive Plots ---\n",
        "\n",
        "# compute the mean reaction times and standard deviations for different\n",
        "# Valence-Condition combinations\n",
        "valence_side_combinations = df_ET.groupby(['valence_looked', 'side_looked'])['rt'].agg(['mean', 'std']).reset_index()\n",
        "\n",
        "# adjust the order of combinations\n",
        "valence_side_combinations = valence_side_combinations.sort_values(['side_looked', 'valence_looked'], ascending=[True, False])\n",
        "\n",
        "# save means and standard deviations\n",
        "combinations = ['left positive', 'left negative', 'right positive', 'right negative']\n",
        "means = valence_side_combinations['mean']\n",
        "std_devs = valence_side_combinations['std']\n",
        "\n",
        "# plot the different mean reaction times\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(combinations, means, yerr=std_devs, capsize=5,\n",
        "               color=['lightblue', 'gold', 'blue', 'orange'], label=combinations)\n",
        "\n",
        "# add values for means and standard deviations to the bars\n",
        "for i, (bar, mean, std_dev) in enumerate(zip(bars, means, std_devs)):\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width()/2,\n",
        "        mean,\n",
        "        f\"{mean:.2f}\\n±{std_dev:.2f}\",\n",
        "        ha=\"center\",\n",
        "        va=\"center\",\n",
        "        fontsize=12,\n",
        "        color=\"black\",\n",
        "        fontweight=\"bold\",\n",
        "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", edgecolor=\"none\", alpha=0.7)\n",
        "    )\n",
        "\n",
        "# define plot labels and design details\n",
        "plt.ylabel('Mean Reaction Time (ms)', fontsize = 13)\n",
        "plt.xticks([], rotation=45)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Zc654V9bulsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the mean reaction times for different Valence Arousal-Difference combinations\n",
        "valence_arousal_diff_combinations = df_ET.groupby(['valence_looked', 'arousal_difference'])['rt'].agg(['mean']).reset_index()\n",
        "\n",
        "# create a data frame with all combinations for Valence and Arousal-Difference\n",
        "all_combinations = {\n",
        "    'arousal_difference': np.append(np.arange(-6,7), np.arange(-6,7)),\n",
        "    'valence_looked': np.append(np.zeros(13, dtype = int), np.ones(13, dtype=int))\n",
        "}\n",
        "all_combs = pd.DataFrame(all_combinations)\n",
        "\n",
        "# merge both frames together for plotting\n",
        "df_complete = pd.merge(all_combs, valence_arousal_diff_combinations, on=['arousal_difference', 'valence_looked'], how='left')\n",
        "\n",
        "# split up into positive and negative for color-coding in the plot\n",
        "pos_data = df_complete[df_complete['valence_looked'] == 1]\n",
        "neg_data = df_complete[df_complete['valence_looked'] == 0]\n",
        "\n",
        "# create subplots\n",
        "fig = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# define the positions of the bars\n",
        "bar_position_positive = np.arange(len(pos_data))\n",
        "bar_position_negative = [x + 0.3 for x in bar_position_positive]\n",
        "\n",
        "# plot the positive and negative bars\n",
        "plt.bar(bar_position_positive, pos_data['mean'], color='g', width=0.3, label='positive')\n",
        "plt.bar(bar_position_negative, neg_data['mean'], color='r', width=0.3, label='negative')\n",
        "\n",
        "# define plot labels and design details\n",
        "plt.xlabel('Arousal-Difference', fontsize=15)\n",
        "plt.ylabel('Mean Reaction Time (ms)', fontsize=15)\n",
        "plt.xticks(np.arange(0.15, 13.15, step=1), labels = pos_data['arousal_difference'], fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.legend(loc='upper right', fontsize=12)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZHDfQVtbGJnZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}